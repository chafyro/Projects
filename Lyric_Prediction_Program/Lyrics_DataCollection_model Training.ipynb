{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d7cb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb8f6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_nelly = 'https://www.lyrics.com/artist/Nelly-Furtado/451535'\n",
    "url_russ = 'https://www.lyrics.com/artist/Russ-Morgan/7176'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5fa2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_nelly = requests.get(url_nelly)\n",
    "if response_nelly.status_code == 200:\n",
    "    furtado_ly = response_nelly.text\n",
    "    with open(\"nelly.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(furtado_ly)\n",
    "    print(\"Nelly Furtado page saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bb3d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_russ = requests.get(url_russ)\n",
    "if response_russ.status_code == 200:\n",
    "    russmorgan = response_russ.text\n",
    "    with open(\"russmorgan.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(russmorgan)\n",
    "    print(\"Russ Morgan page saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e32fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nelly.txt', 'r', encoding=\"utf-8\") as my_file:\n",
    "    meep = my_file.read()\n",
    "    songs = re.findall(r'/lyric/\\d+', meep)\n",
    "\n",
    "with open('russmorgan.txt', 'r') as my_file:\n",
    "    meep2 = my_file.read()\n",
    "    songs2 = re.findall(r'/lyric/\\d+', meep2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dee16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lyur = []\n",
    "sub_url = 'https://www.lyrics.com'\n",
    "for song in songs:\n",
    "    sub_link = sub_url + song\n",
    "    lyur.append(sub_link)\n",
    "\n",
    "lyur2 = []\n",
    "for song in songs2:\n",
    "    sub_link = sub_url + song\n",
    "    lyur2.append(sub_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98f8e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_texts = []\n",
    "for index, element in enumerate(lyur):\n",
    "    header = {'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:24.0) Gecko/20100101 Firefox/24.0'}\n",
    "    response_nelly_lyric = requests.get(element, headers=header)\n",
    "    furtado_ly_ly = response_nelly_lyric.text\n",
    "\n",
    "    with open(f'nelly_{index}.txt', \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(furtado_ly_ly)\n",
    "\n",
    "    song_content = response_nelly_lyric.text\n",
    "    song_soup = BeautifulSoup(song_content, 'html.parser')\n",
    "\n",
    "    title_element = song_soup.find('h1', class_='lyric-title')\n",
    "    title = title_element.text.strip() if title_element is not None else ''\n",
    "\n",
    "    lyrics_texts.append({'Links': element, 'Title': title, 'Lyrics': ''})\n",
    "\n",
    "    os.makedirs('Nelly Furtado', exist_ok=True)  # Create directory if it doesn't exist\n",
    "\n",
    "    lyrics_div = song_soup.find('pre', id='lyric-body-text')\n",
    "\n",
    "    if lyrics_div:\n",
    "        lyrics = lyrics_div.get_text(strip=True)\n",
    "        with open(f'Nelly Furtado/nelly_lyrics_{index}.txt', 'w', encoding='utf-8') as file:\n",
    "            file.write(lyrics)\n",
    "\n",
    "        lyrics_texts[index]['Lyrics'] = lyrics\n",
    "\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76957e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_texts2 = []\n",
    "for index, element in enumerate(lyur2):\n",
    "    header = {'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:24.0) Gecko/20100101 Firefox/24.0'}\n",
    "    response_russ_lyric = requests.get(element, headers=header)\n",
    "    russ_ly_ly = response_russ_lyric.text\n",
    "\n",
    "    with open(f'russ_{index}.txt', \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(russ_ly_ly)\n",
    "\n",
    "    song_content = response_russ_lyric.text\n",
    "    song_soup = BeautifulSoup(song_content, 'html.parser')\n",
    "\n",
    "    title_element = song_soup.find('h1', class_='lyric-title')\n",
    "    title = title_element.text.strip() if title_element is not None else ''\n",
    "\n",
    "    lyrics_texts2.append({'Links': element, 'Title': title, 'Lyrics': ''})\n",
    "\n",
    "    os.makedirs('russ_morgan', exist_ok=True)  # Create directory if it doesn't exist\n",
    "\n",
    "    lyrics_div = song_soup.find('pre', id='lyric-body-text')\n",
    "\n",
    "    if lyrics_div:\n",
    "        lyrics = lyrics_div.get_text(strip=True)\n",
    "        with open(f'russ_morgan/russ_lyrics_{index}.txt', 'w', encoding='utf-8') as file:\n",
    "            file.write(lyrics)\n",
    "\n",
    "        lyrics_texts2[index]['Lyrics'] = lyrics\n",
    "\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e193da",
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_folders = [\"Nelly Furtado\", \"russ_morgan\"]\n",
    "corpus = []\n",
    "labels = []\n",
    "\n",
    "for artist_folder in lyrics_folders:\n",
    "    for filename in os.listdir(artist_folder):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(artist_folder, filename)\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                lyrics = file.read()\n",
    "                corpus.append(lyrics)\n",
    "                labels.append(artist_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254c0555",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download(\"wordnet\")\n",
    "nltk.download('stopwords')\n",
    "\n",
    "corpus = [s.lower() for s in corpus]\n",
    "\n",
    "CLEAN_corpus = []\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "for doc in corpus:\n",
    "    tokens = tokenizer.tokenize(text=doc)\n",
    "    clean_doc = \" \".join(lemmatizer.lemmatize(token) for token in tokens)\n",
    "    CLEAN_corpus.append(clean_doc)\n",
    "\n",
    "STOPWORDS = stopwords.words('english')\n",
    "\n",
    "LABELS = ['Nelly Furtado']  + ['Russ Morgan']\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "\n",
    "def tokenize_lemmatize(text, stopwords=STOPWORDS, tokenizer=tokenizer, lemmatizer=lemmatizer):\n",
    "    text = ''.join([ch for ch in text if ch not in string.punctuation])\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens if token not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a44cd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words=STOPWORDS)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "X_df = pd.DataFrame(X.todense(), columns=vectorizer.get_feature_names_out(), index=labels)\n",
    "\n",
    "X = X_df.values  # Features (word frequencies)\n",
    "y = X_df.index.values  # Labels (artist names)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce21fff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e401e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_artist(text, vectorizer=vectorizer, model=model):\n",
    "    processed_text = ' '.join(tokenize_lemmatize(text.lower()))\n",
    "    features = vectorizer.transform([processed_text])\n",
    "    predicted_artist = model.predict(features)\n",
    "    return predicted_artist[0]\n",
    "\n",
    "\n",
    "# Use the function to predict artist\n",
    "text = \"Thebirdsabove all sing of love, agentlesweet\"\n",
    "predicted_artist = predict_artist(text)\n",
    "print(\"Predicted Artist:\", predicted_artist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef1ba22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('trained_model.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(model, pickle_file)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
